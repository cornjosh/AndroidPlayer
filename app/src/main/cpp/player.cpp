//
// player.cpp
// Created by zylnt on 2025/3/30.
//

#include <jni.h>
#include <string>
#include <thread>
#include "log.h"
#define TAG "player"
#include "packetQueue.h"
#include "frameQueue.h"
#include "audioRingBuffer.h"
#include "timer.h"

extern "C" {
#include <libavformat/avformat.h>
#include <android/native_window_jni.h>
}

// å…¨å±€èµ„æº
static PacketQueue* packetQueue = nullptr;
static FrameQueue* frameQueue = nullptr;
static AVFormatContext* formatCtx = nullptr;
static int videoStreamIndex = -1;
static int audioStreamIndex = -1;
static AVRational videoTimeBase;
static ANativeWindow* nativeWindow = nullptr;
static std::string videoPath;
static PacketQueue* audioPacketQueue = nullptr;
static AudioRingBuffer* audioRingBuffer = new AudioRingBuffer(9600000);
static Timer timer;
static bool isInited = false; // æ˜¯å¦åˆå§‹åŒ–å®Œæˆ




// çº¿ç¨‹å¥æŸ„
static std::thread demuxerThread;
static std::thread decoderThread;
static std::thread rendererThread;
static std::thread audioDecoderThread;
static std::thread aAudioPlayerThread;

extern void demuxThread(const char* path, PacketQueue* videoQueue, PacketQueue* audioQueue, int videoStreamIndex, int audioStreamIndex);
extern void decodeThread(PacketQueue* packetQueue, FrameQueue* frameQueue, AVCodecParameters* codecpar);
extern void renderThread(FrameQueue* frameQueue, ANativeWindow* window, AVRational time_base);
extern void audioDecodeThread(PacketQueue* packetQueue, AudioRingBuffer* ringBuffer, AVCodecParameters* codecpar);
extern void AAudioPlayerThread(AudioRingBuffer* ringBuffer);


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativePlay(JNIEnv *env, jobject thiz, jstring file,
                                                 jobject surface) {
    if (isInited){
        timer.resume();
        return 0;
    }
    Timer::isPlaying = true; // è®¾ç½®ä¸ºæ­£åœ¨æ’­æ”¾

    // å¤„ç†æ–‡ä»¶è·¯å¾„
    const char* src = env->GetStringUTFChars(file, nullptr);
    videoPath = src;
    env->ReleaseStringUTFChars(file, src);
    LOGI("ğŸ“ nativeSetDataSource: %s", videoPath.c_str());

    // è®¾ç½® surface
    if (nativeWindow) {
        ANativeWindow_release(nativeWindow);
        nativeWindow = nullptr;
    }
    nativeWindow = ANativeWindow_fromSurface(env, surface);
    if (!nativeWindow) {
        LOGE("âŒ ANativeWindow_fromSurface failed! surface is null.");
        return -1;
    }

    LOGI("âœ… nativeSetSurface success: window=%p", nativeWindow);

    LOGI("â–¶ï¸ nativeStart");

    // åˆå§‹åŒ–å…¨å±€çŠ¶æ€
    avformat_network_init();

    packetQueue = new PacketQueue();        // video
    audioPacketQueue = new PacketQueue();   // âœ… audio
    frameQueue = new FrameQueue();

    // æ‰“å¼€è§†é¢‘è·å– AVFormatContext
    if (avformat_open_input(&formatCtx, videoPath.c_str(), nullptr, nullptr) != 0) {
        LOGE("âŒ Failed to open input file.");
        return -1;
    }

    if (avformat_find_stream_info(formatCtx, nullptr) < 0) {
        LOGE("âŒ Failed to find stream info.");
        return -2;
    }

    // æ‰¾åˆ°è§†é¢‘æµå’ŒéŸ³é¢‘æµç´¢å¼•
    for (unsigned int i = 0; i < formatCtx->nb_streams; i++) {
        if (formatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoStreamIndex = i;
            videoTimeBase = formatCtx->streams[i]->time_base;
            LOGI("ğŸ¥ Video stream index: %d", videoStreamIndex);
        }
        if (formatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO){
            audioStreamIndex = i;
            LOGI("ğŸµ Audio stream index: %d", audioStreamIndex);
        }
    }

    if (videoStreamIndex == -1) {
        LOGE("âŒ No video stream found.");
        return -3;
    }

    if (audioStreamIndex == -1) {
        LOGE("âŒ No audio stream found.");
        return -4;
    }

    LOGI("ğŸ“¦ Starting demux/decode/render threads...");

    demuxerThread = std::thread(demuxThread, videoPath.c_str(), packetQueue, audioPacketQueue, videoStreamIndex, audioStreamIndex);
    decoderThread = std::thread(decodeThread, packetQueue, frameQueue,
                                formatCtx->streams[videoStreamIndex]->codecpar);
    rendererThread = std::thread(renderThread, frameQueue, nativeWindow, videoTimeBase);
    audioDecoderThread = std::thread(audioDecodeThread, audioPacketQueue, audioRingBuffer,
                                formatCtx->streams[audioStreamIndex]->codecpar);
    aAudioPlayerThread = std::thread(AAudioPlayerThread, audioRingBuffer);

    timer.setCurrentTime(0); // è®¾ç½®åˆå§‹æ—¶é—´ä¸º 0
    timer.setTimeSpeed(1.0); // è®¾ç½®æ—¶é—´å€ç‡ä¸º 1.0
    timer.start(); // å¯åŠ¨è®¡æ—¶å™¨çº¿ç¨‹
    LOGI("â±ï¸ Timer started with initial time: %.3f", Timer::getCurrentTime());


    // å¯é€‰ï¼šdetach æˆ– join ç®¡ç†çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸ
    demuxerThread.detach();
    decoderThread.detach();
    rendererThread.detach();
    audioDecoderThread.detach();
    aAudioPlayerThread.detach();

    isInited = true;

    return 0;
}



extern "C"
JNIEXPORT void JNICALL
Java_com_example_androidplayer_Player_nativePause(JNIEnv *env, jobject thiz, jboolean p) {
    timer.pause();
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeSeek(JNIEnv *env, jobject thiz, jdouble position) {
    timer.setCurrentTime(position);
    return 0;
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeStop(JNIEnv *env, jobject thiz) {
    LOGI("ğŸ›‘ nativeStop called");
//    isPlaying = false;

    // åœæ­¢ä¸»æ—¶é’Ÿ
    timer.pause();
    timer.setCurrentTime(0);
    Timer::isPlaying = false;

    // é‡Šæ”¾ native window
    if (nativeWindow) {
        ANativeWindow_release(nativeWindow);
        nativeWindow = nullptr;
        LOGI("ğŸ§¹ Released ANativeWindow");
    }

    // å…³é—­å¹¶é‡Šæ”¾ AVFormatContext
    if (formatCtx) {
        avformat_close_input(&formatCtx);  // è‡ªåŠ¨é‡Šæ”¾ streams
        formatCtx = nullptr;
        LOGI("ğŸ§¹ Closed AVFormatContext");
    }

    // é‡Šæ”¾ PacketQueueï¼ˆvideoï¼‰
    if (packetQueue) {
        delete packetQueue;
        packetQueue = nullptr;
        LOGI("ğŸ§¹ Deleted video PacketQueue");
    }

    // é‡Šæ”¾ PacketQueueï¼ˆaudioï¼‰
    if (audioPacketQueue) {
        delete audioPacketQueue;
        audioPacketQueue = nullptr;
        LOGI("ğŸ§¹ Deleted audio PacketQueue");
    }

    // é‡Šæ”¾ FrameQueue
    if (frameQueue) {
        delete frameQueue;
        frameQueue = nullptr;
        LOGI("ğŸ§¹ Deleted FrameQueue");
    }

    // é‡å»º AudioRingBufferï¼ˆæˆ–ä½ ä¹Ÿå¯ä»¥æ·»åŠ  clear å‡½æ•°ï¼‰
    if (audioRingBuffer) {
        delete audioRingBuffer;
        audioRingBuffer = new AudioRingBuffer(9600000);  // é¢„åˆ†é…ä¸€æ ·å¤§å°
        LOGI("ğŸ”„ Reset AudioRingBuffer");
    }

    // æ¸…ç©ºè§†é¢‘è·¯å¾„å’Œæµç´¢å¼•
    videoPath.clear();
    videoStreamIndex = -1;
    audioStreamIndex = -1;

    isInited = false;

    LOGI("âœ… All playback resources cleaned up");
    return 0;
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeSetSpeed(JNIEnv *env, jobject thiz, jfloat speed) {
    timer.setTimeSpeed(speed);
    return 0;
}


extern "C"
JNIEXPORT jdouble JNICALL
Java_com_example_androidplayer_Player_nativeGetPosition(JNIEnv *env, jobject thiz) {
    return timer.getCurrentTime();
}



extern "C"
JNIEXPORT jdouble JNICALL
Java_com_example_androidplayer_Player_nativeGetDuration(JNIEnv *env, jobject thiz) {
    if (formatCtx == nullptr) {
        LOGE("âŒ Format context is null, cannot get duration");
        return -1; // é”™è¯¯å¤„ç†ï¼šè¿”å› -1 è¡¨ç¤ºæ— æ³•è·å–æ—¶é•¿
    }

    // è·å–è§†é¢‘æ—¶é•¿ï¼ˆå•ä½ï¼šå¾®ç§’ï¼‰ï¼Œå¹¶è½¬æ¢ä¸ºç§’
    double durationInSeconds = formatCtx->duration / AV_TIME_BASE;
    LOGI("â³ Video duration: %.3f seconds", durationInSeconds);

    return durationInSeconds;
}