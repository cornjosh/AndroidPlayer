//
// player.cpp
// Created by zylnt on 2025/3/30.
//

#include <jni.h>
#include <string>
#include <thread>
#include "log.h"
#define TAG "player"
#include "packetQueue.h"
#include "frameQueue.h"
#include "audioRingBuffer.h"
#include "timer.h"

extern "C" {
#include <libavformat/avformat.h>
#include <android/native_window_jni.h>
}

// å…¨å±€èµ„æº
static PacketQueue* packetQueue = nullptr;
static FrameQueue* frameQueue = nullptr;
static AVFormatContext* formatCtx = nullptr;
static int videoStreamIndex = -1;
static int audioStreamIndex = -1;
static AVRational videoTimeBase;
static ANativeWindow* nativeWindow = nullptr;
static std::string videoPath;
static PacketQueue* audioPacketQueue = nullptr;
static AudioRingBuffer* audioRingBuffer = new AudioRingBuffer(9600000);
static Timer timer;

// çº¿ç¨‹åŒæ­¥å˜é‡




// çº¿ç¨‹å¥æŸ„
static std::thread demuxerThread;
static std::thread decoderThread;
static std::thread rendererThread;
static std::thread audioDecoderThread;
static std::thread aAudioPlayerThread;

extern void demuxThread(const char* path, PacketQueue* videoQueue, PacketQueue* audioQueue, int videoStreamIndex, int audioStreamIndex);
extern void decodeThread(PacketQueue* packetQueue, FrameQueue* frameQueue, AVCodecParameters* codecpar);
extern void renderThread(FrameQueue* frameQueue, ANativeWindow* window, AVRational time_base);
extern void audioDecodeThread(PacketQueue* packetQueue, AudioRingBuffer* ringBuffer, AVCodecParameters* codecpar);
extern void AAudioPlayerThread(AudioRingBuffer* ringBuffer);


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativePlay(JNIEnv *env, jobject thiz, jstring file,
                                                 jobject surface) {
    // å¤„ç†æ–‡ä»¶è·¯å¾„
    const char* src = env->GetStringUTFChars(file, nullptr);
    videoPath = src;
    env->ReleaseStringUTFChars(file, src);
    LOGI("ğŸ“ nativeSetDataSource: %s", videoPath.c_str());

    // è®¾ç½® surface
    if (nativeWindow) {
        ANativeWindow_release(nativeWindow);
        nativeWindow = nullptr;
    }
    nativeWindow = ANativeWindow_fromSurface(env, surface);
    if (!nativeWindow) {
        LOGE("âŒ ANativeWindow_fromSurface failed! surface is null.");
        return -1;
    }

    LOGI("âœ… nativeSetSurface success: window=%p", nativeWindow);

    LOGI("â–¶ï¸ nativeStart");

    // åˆå§‹åŒ–å…¨å±€çŠ¶æ€
    avformat_network_init();

    packetQueue = new PacketQueue();        // video
    audioPacketQueue = new PacketQueue();   // âœ… audio
    frameQueue = new FrameQueue();

    // æ‰“å¼€è§†é¢‘è·å– AVFormatContext
    if (avformat_open_input(&formatCtx, videoPath.c_str(), nullptr, nullptr) != 0) {
        LOGE("âŒ Failed to open input file.");
        return -1;
    }

    if (avformat_find_stream_info(formatCtx, nullptr) < 0) {
        LOGE("âŒ Failed to find stream info.");
        return -2;
    }

    // æ‰¾åˆ°è§†é¢‘æµå’ŒéŸ³é¢‘æµç´¢å¼•
    for (unsigned int i = 0; i < formatCtx->nb_streams; i++) {
        if (formatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoStreamIndex = i;
            videoTimeBase = formatCtx->streams[i]->time_base;
            LOGI("ğŸ¥ Video stream index: %d", videoStreamIndex);
        }
        if (formatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO){
            audioStreamIndex = i;
            LOGI("ğŸµ Audio stream index: %d", audioStreamIndex);
        }
    }

    if (videoStreamIndex == -1) {
        LOGE("âŒ No video stream found.");
        return -3;
    }

    if (audioStreamIndex == -1) {
        LOGE("âŒ No audio stream found.");
        return -4;
    }

    LOGI("ğŸ“¦ Starting demux/decode/render threads...");

    demuxerThread = std::thread(demuxThread, videoPath.c_str(), packetQueue, audioPacketQueue, videoStreamIndex, audioStreamIndex);
    decoderThread = std::thread(decodeThread, packetQueue, frameQueue,
                                formatCtx->streams[videoStreamIndex]->codecpar);
    rendererThread = std::thread(renderThread, frameQueue, nativeWindow, videoTimeBase);
    audioDecoderThread = std::thread(audioDecodeThread, audioPacketQueue, audioRingBuffer,
                                formatCtx->streams[audioStreamIndex]->codecpar);
    aAudioPlayerThread = std::thread(AAudioPlayerThread, audioRingBuffer);

    timer.setCurrentTime(-1); // è®¾ç½®åˆå§‹æ—¶é—´ä¸º -1ï¼Œè¡¨ç¤ºæœªå¼€å§‹æ’­æ”¾
    timer.setTimeSpeed(1.0); // è®¾ç½®æ—¶é—´å€ç‡ä¸º 1.0
    timer.start(); // å¯åŠ¨è®¡æ—¶å™¨çº¿ç¨‹
    LOGI("â±ï¸ Timer started with initial time: %.3f", Timer::getCurrentTime());


    // å¯é€‰ï¼šdetach æˆ– join ç®¡ç†çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸ
    demuxerThread.detach();
    decoderThread.detach();
    rendererThread.detach();
    audioDecoderThread.detach();
    aAudioPlayerThread.detach();

    return 0;
}



extern "C"
JNIEXPORT void JNICALL
Java_com_example_androidplayer_Player_nativePause(JNIEnv *env, jobject thiz, jboolean p) {
    // TODO: implement nativePause()
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeSeek(JNIEnv *env, jobject thiz, jdouble position) {
    // TODO: implement nativeSeek()
    return 0;
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeStop(JNIEnv *env, jobject thiz) {
    // TODO: implement nativeStop()
    return 0;
}


extern "C"
JNIEXPORT jint JNICALL
Java_com_example_androidplayer_Player_nativeSetSpeed(JNIEnv *env, jobject thiz, jfloat speed) {
    // TODO: implement nativeSetSpeed()
    return 0;
}


extern "C"
JNIEXPORT jdouble JNICALL
Java_com_example_androidplayer_Player_nativeGetPosition(JNIEnv *env, jobject thiz) {
    // TODO: implement nativeGetPosition()
    return 0;
}



extern "C"
JNIEXPORT jdouble JNICALL
Java_com_example_androidplayer_Player_nativeGetDuration(JNIEnv *env, jobject thiz) {
    // TODO: implement nativeGetDuration()
    return 0;
}